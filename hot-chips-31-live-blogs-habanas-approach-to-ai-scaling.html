<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Habana's Approach to AI Scaling - JadeVibe</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="09:21PM EDT - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute. 09:21PM EDT - Goya and Gaudi 09:22PM EDT - Recapping Training vs Inference requirements"><meta name=robots content="index,follow,noarchive"><meta property="og:title" content="Habana's Approach to AI Scaling"><meta property="og:description" content="09:21PM EDT - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute. 09:21PM EDT - Goya and Gaudi 09:22PM EDT - Recapping Training vs Inference requirements"><meta property="og:type" content="article"><meta property="og:url" content="/hot-chips-31-live-blogs-habanas-approach-to-ai-scaling.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-09-19T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-19T00:00:00+00:00"><meta itemprop=name content="Habana's Approach to AI Scaling"><meta itemprop=description content="09:21PM EDT - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute. 09:21PM EDT - Goya and Gaudi 09:22PM EDT - Recapping Training vs Inference requirements"><meta itemprop=datePublished content="2024-09-19T00:00:00+00:00"><meta itemprop=dateModified content="2024-09-19T00:00:00+00:00"><meta itemprop=wordCount content="669"><meta itemprop=keywords content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/mainroad/css/style.css><link rel="shortcut icon" href=./favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=./index.html title=JadeVibe rel=home><div class="logo__item logo__text"><div class=logo__title>JadeVibe</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Habana's Approach to AI Scaling</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-09-19T00:00:00Z>September 19, 2024</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=./categories/blog/ rel=category>blog</a></span></div></div></header><div class="content post__content clearfix"><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184445_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184403_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212118 href=#><span class=lb_time>09:21PM EDT</span></a> - The final talk today at Hot Chips is from Habana, who is discussing its approach to how to scale AI compute.</p><p><a id=post0819212122 href=#><span class=lb_time>09:21PM EDT</span></a> - Goya and Gaudi</p><p><a id=post0819212202 href=#><span class=lb_time>09:22PM EDT</span></a> - Recapping Training vs Inference requirements</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182142_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212411 href=#><span class=lb_time>09:24PM EDT</span></a> - Goya processor architecure</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182354_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212428 href=#><span class=lb_time>09:24PM EDT</span></a> - 3 engines, RPC, GEMM, and DMA. Work Concurrently with shared SRAM</p><p><a id=post0819212439 href=#><span class=lb_time>09:24PM EDT</span></a> - TPC is VLIW SIMD core, C-programmable</p><p><a id=post0819212445 href=#><span class=lb_time>09:24PM EDT</span></a> - PCIe Gen 4.0 x16</p><p><a id=post0819212457 href=#><span class=lb_time>09:24PM EDT</span></a> - Two DDR4-2666 channels, built on TSMC 16</p><p><a id=post0819212508 href=#><span class=lb_time>09:25PM EDT</span></a> - Supports UINT8 to FP32</p><p><a id=post0819212519 href=#><span class=lb_time>09:25PM EDT</span></a> - Dedicated HW and TPC ISA for special function acceneration</p><p><a id=post0819212555 href=#><span class=lb_time>09:25PM EDT</span></a> - Have to adjust quantization to mix accuracy vs power</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182600_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212646 href=#><span class=lb_time>09:26PM EDT</span></a> - PCIe card - Software stack is more important.</p><p><a id=post0819212658 href=#><span class=lb_time>09:26PM EDT</span></a> - Habana is a software company that just happens to do hardware</p><p><a id=post0819212719 href=#><span class=lb_time>09:27PM EDT</span></a> - Graph compiler with built-in quantization engine</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182703_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212730 href=#><span class=lb_time>09:27PM EDT</span></a> - Multiple recipes can be loaded for the hardware</p><p><a id=post0819212801 href=#><span class=lb_time>09:28PM EDT</span></a> - Goya supports models trained on any processor: CPU, GPU, TPU, Gaudi etc</p><p><a id=post0819212837 href=#><span class=lb_time>09:28PM EDT</span></a> - Users can create custom layers and kernels</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182844_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212918 href=#><span class=lb_time>09:29PM EDT</span></a> - Still market leader since benchmarks made 11 months ago vs common CPU/GPU</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_182931_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819212948 href=#><span class=lb_time>09:29PM EDT</span></a> - New for today, natural language benchmark results</p><p><a id=post0819213004 href=#><span class=lb_time>09:30PM EDT</span></a> - Support BERT architecture on Goya</p><p><a id=post0819213019 href=#><span class=lb_time>09:30PM EDT</span></a> - GEMMs and TPCs are fully utilized</p><p><a id=post0819213027 href=#><span class=lb_time>09:30PM EDT</span></a> - Chip was designed long before BERT was invested</p><p><a id=post0819213029 href=#><span class=lb_time>09:30PM EDT</span></a> - invented</p><p><a id=post0819213039 href=#><span class=lb_time>09:30PM EDT</span></a> - High degree of accuracy when quantized</p><p><a id=post0819213044 href=#><span class=lb_time>09:30PM EDT</span></a> - Software managed SRAM</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183054_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213135 href=#><span class=lb_time>09:31PM EDT</span></a> - Now Gaudi, the training processor</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183121_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213150 href=#><span class=lb_time>09:31PM EDT</span></a> - Performance at Scale, high throughput at low batch size, high power efficiency</p><p><a id=post0819213207 href=#><span class=lb_time>09:32PM EDT</span></a> - Enable native ethernet scale out - on chip RDMA over Converged Ethernet</p><p><a id=post0819213225 href=#><span class=lb_time>09:32PM EDT</span></a> - Open Compute Project Accelerator Module: OAM = (OCP)AM</p><p><a id=post0819213237 href=#><span class=lb_time>09:32PM EDT</span></a> - Framework and ML compiler support, rich TPC Kernet Library</p><p><a id=post0819213257 href=#><span class=lb_time>09:32PM EDT</span></a> - Architecture looks similar to Goya</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183241_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213305 href=#><span class=lb_time>09:33PM EDT</span></a> - Networking has changed, memory has changed</p><p><a id=post0819213318 href=#><span class=lb_time>09:33PM EDT</span></a> - PCIe 4.0 x16, 4x8GB HBM</p><p><a id=post0819213325 href=#><span class=lb_time>09:33PM EDT</span></a> - 10x 100 GbE, or 20x50 GbE</p><p><a id=post0819213340 href=#><span class=lb_time>09:33PM EDT</span></a> - Supports UINT8 to FP32 and BF16</p><p><a id=post0819213417 href=#><span class=lb_time>09:34PM EDT</span></a> - SW supports profiling tools</p><p><a id=post0819213447 href=#><span class=lb_time>09:34PM EDT</span></a> - Only AI Training chip with RoCE v2</p><p><a id=post0819213509 href=#><span class=lb_time>09:35PM EDT</span></a> - NVIDIA was first to showcase RoCE v2 for AI, but they haven't implemented it yet</p><p><a id=post0819213608 href=#><span class=lb_time>09:36PM EDT</span></a> - NVIDIA GPU is much more complex with RoCE v2 support via Mellanox</p><p><a id=post0819213614 href=#><span class=lb_time>09:36PM EDT</span></a> - Gaudi integrates both</p><p><a id=post0819213632 href=#><span class=lb_time>09:36PM EDT</span></a> - Supports Lossless and Lossy fabrics</p><p><a id=post0819213641 href=#><span class=lb_time>09:36PM EDT</span></a> - Advanced congestion controls</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183432_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183525_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183548_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183715_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213740 href=#><span class=lb_time>09:37PM EDT</span></a> - Customers can buy OAM cards or an 8 card Server</p><p><a id=post0819213816 href=#><span class=lb_time>09:38PM EDT</span></a> - Server box has no CPU, up to customer to config to needed. Uses mini-SAS HD</p><p><a id=post0819213831 href=#><span class=lb_time>09:38PM EDT</span></a> - Ethernet connectivity for point-to-point links with non-blocking full mesh</p><p><a id=post0819213842 href=#><span class=lb_time>09:38PM EDT</span></a> - 3 ports per card for scale up</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183747_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213905 href=#><span class=lb_time>09:39PM EDT</span></a> - Can choose ratio of CPUs to Gaudi cards</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183849_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819213931 href=#><span class=lb_time>09:39PM EDT</span></a> - Gaudi vs DGX</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_183918_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819214037 href=#><span class=lb_time>09:40PM EDT</span></a> - Unlike DGX, do not force user to separate PCIe between management and scaleout. Gaudi offers separate PCIe ports</p><p><a id=post0819214103 href=#><span class=lb_time>09:41PM EDT</span></a> - PCIe card dual slot also available</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184043_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819214105 href=#><span class=lb_time>09:41PM EDT</span></a> - HL-200</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/14760/IMG_20190819_184117_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0819214133 href=#><span class=lb_time>09:41PM EDT</span></a> - Data parallel possible, model parallel possible</p><p><a id=post0819214440 href=#><span class=lb_time>09:44PM EDT</span></a> - Can leapfrog performance over DGX-2 due to better connectivity. Can connect 64 gaudi chips with non-blocking throughput</p><p><a id=post0819214538 href=#><span class=lb_time>09:45PM EDT</span></a> - Q&A time</p><p><a id=post0819214645 href=#><span class=lb_time>09:46PM EDT</span></a> - Q: What type of quantization requires a processor? There is no quantization processor. There's a software engine that takes an FP32 model and can quantize to data types that are more efficient and gives the feedback on the accuracy</p><p><a id=post0819214740 href=#><span class=lb_time>09:47PM EDT</span></a> - Q: Can you comment on interconnectivity of GEMM? A: It's one functional unit.</p><p><a id=post0819214818 href=#><span class=lb_time>09:48PM EDT</span></a> - Q: What is the minimum viable for an IoT gateway? A: You can use a single card. You can put a gaudi in a single PCIe slot.</p><p><a id=post0819214833 href=#><span class=lb_time>09:48PM EDT</span></a> - That's a wrap for today. More talks tomorrow!</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH51g5VpZqGnpGKwqbXPrGRsaV2htrexjJujqJ%2BjYrWirsCnmKxlkaW9s7vAnJ9mrJ9irqp50pyYpaGenA%3D%3D</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=./michael-oher-dating-and-relationship-status.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Is Michael Oher Married? Is The NFL Star And Subject Of Blind Side Dating Tabitha Soren?</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=./the-weight-in-is-friday-between-marcus-browne-and-badou-jack-gets-nasty.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Friday's weight-in between Marcus Browne and Badou Jack Gets Nasty</p></a></div></nav></div><aside class=sidebar><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./chrishell-stause-works-up-a-sweat-in-steamy-bikini-workout-with-her-new-beau-jason-oppenheim.html>Chrishell Stause works up a sweat in steamy bikini workout with her new beau Jason Oppenheim</a></li><li class=widget__item><a class=widget__link href=./gabrielle-reece-net-worth-146437.html>Gabrielle Reece Net Worth</a></li><li class=widget__item><a class=widget__link href=./how-old-are-joe-goldberg-and-love-quinn-in-you.html>How Old Are Joe Goldberg and Love Quinn in You?</a></li><li class=widget__item><a class=widget__link href=./celebrity-hairstyles.html>Kaley Cuoco's Beauty Transformation</a></li><li class=widget__item><a class=widget__link href=./lana-rhoades-movie-actress-net-worth-237779.html>Lana Rhoades Net Worth 2024</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./categories/blog/>blog</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 JadeVibe.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=https://assets.cdnweb.info/hugo/mainroad/js/menu.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>